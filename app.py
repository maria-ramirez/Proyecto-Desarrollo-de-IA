# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fOnVt1kyB91eiU7yD0m1LrMXqrpSfWUl
"""

from __future__ import division, print_function
# coding=utf-8
import sys
import os
import glob
import re
import numpy as np
import imutils
from google.colab.patches import cv2_imshow

# Keras
from keras.applications.imagenet_utils import preprocess_input, decode_predictions
from keras.models import load_model
from keras.preprocessing import image

# Flask utils
from flask import Flask, redirect, url_for, request, render_template
from werkzeug.utils import secure_filename
from gevent.pywsgi import WSGIServer

# Define a flask app
app = Flask(__name__)

# Model saved with Keras model.save()
MODEL_PATH = 'models/cnn_basico.h5'

# Load your trained model
model = load_model(MODEL_PATH)
model._make_predict_function()          # Necessary
# print('Model loaded. Start serving...')

# You can also use pretrained model from Keras
# Check https://keras.io/applications/
#from keras.applications.resnet50 import ResNet50
#model = ResNet50(weights='imagenet')
#model.save('')
print('Model loaded. Check http://127.0.0.1:5000/')


#Función que llama al modelo para deteccion de los bordes y clasificacion de caracteres en la imagen

def model_predict(img_path, model):
  
  img = image.load_img(img_path, target_size=(64, 64))
  
  # Preprocesa la imagen
  
  img_t = cv2.resize(img_t, (600, 400))
  img_gray_t = cv2.cvtColor(img_t, cv2.COLOR_RGB2GRAY)
  img_blurred_t = cv2.GaussianBlur(img_gray_t, ksize=(3, 3), sigmaX=0)
  img_thresh_t = cv2.adaptiveThreshold(
    img_blurred_t, 
    maxValue=255.0, 
    adaptiveMethod=cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
    thresholdType=cv2.THRESH_BINARY_INV, 
    blockSize=19, 
    C=9
    )
  
  keypoints = cv2.findContours(img_thresh_t.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
  contours = imutils.grab_contours(keypoints)
  contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10]

  location=None
  for contour in contours:
    approx = cv2.approxPolyDP(contour, 10, True)
    if len (approx) == 4:
      location = approx
      break

  mask = np.zeros(img_gray_t.shape, np.uint8)
  new_img_t = cv2.drawContours(mask, [location], 0,255,-1)
  new_img_t = cv2.bitwise_and(img_t, img_t, mask=mask)

  (x,y) = np.where (mask==255)
  (x1,y1) = (np.min(x), np.min(y))
  (x2,y2) = (np.max(x), np.max(y))
  cropped_img_t = img_t[x1:x2+1, y1:y2+1]
  
  char_test = segment_characters(cropped_img_t)

# Funcion que encuentra caracteres en la imagen recortada (cropped_img)

def segment_characters(image) :

    # Preprocesa la imagen cortada de la placa con binarización
    img = cv2.resize(image, (333, 75))
    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    _, img_binary_lp = cv2.threshold(img_gray, 200, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
    
    # Transformación morfologica para cerrar el shape de los digitos
    img_binary_lp = cv2.dilate(img_binary_lp, (2,2))
    kernel = np.ones((2,2), np.uint8)
    img_binary_lp = cv2.morphologyEx(img_binary_lp, cv2.MORPH_CLOSE, kernel)

    LP_WIDTH = img_binary_lp.shape[0]
    LP_HEIGHT = img_binary_lp.shape[1]

    # Genera bordes blancos
    img_binary_lp[0:3,:] = 255
    img_binary_lp[:,0:3] = 255
    img_binary_lp[72:75,:] = 255
    img_binary_lp[:,330:333] = 255

    # Estima el tamaño de los contornos de caracteres de las placas
    dimensions = [LP_WIDTH/5, LP_WIDTH/1, LP_HEIGHT/17, 2*LP_HEIGHT/3]
   
    # Obtiene los cortornos de la imagen de la placa
    char_list = find_contours(dimensions, img_binary_lp)

    return char_list

# Funcion que encuentra los contornos de la imagen

def find_contours(dimensions, img) :
 
    # Encontrar todos los contornos de la imagen
    cntrs = cv2.findContours(img.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)

    # Recuperar las dimensiones
    lower_width = dimensions[0]
    upper_width = dimensions[1]
    lower_height = dimensions[2]
    upper_height = dimensions[3]

    M = []
    cX = []
    cY = []
   
    # Verifica los 15 contornos mas grandes para identificar el contorno de los caracteres
    cntrs = imutils.grab_contours(cntrs)
    cntrs = sorted(cntrs, key=cv2.contourArea, reverse=True)[:15]
    
    ii = img_binary_lp

    x_cntr_list = []
    target_contours = []
    img_res = []
    for cntr in cntrs :

        # Detecta el contorno en coordenadas binarias y devuelve las coordenadas del rectangulo
        intX, intY, intWidth, intHeight = cv2.boundingRect(cntr)

        # comprobar las dimensiones del contorno para filtrar los caracteres por tamaño del contorno
        if intWidth > lower_width and intWidth < upper_width and intHeight > lower_height and intHeight < upper_height :

            x_cntr_list.append(intX) # Almacenas las coordenadas del contorno

            # Identificación de los centroides

            M = cv2.moments(cntr)
            cX = int(M["m10"] / M["m00"])
            cY = int(M["m01"] / M["m00"])
            #print(cX)
            
            char_copy = np.zeros((44,24))
            
            #Extrae cada caracter usando coordenadas del rectangulo
            
            char = img[intY:intY+intHeight, intX:intX+intWidth]
            char = cv2.resize(char, (20, 40))
                      
            cv2.rectangle(ii, (intX,intY), (intWidth+intX, intY+intHeight), (0,255,0), 2)
            plt.imshow(ii, cmap='gray')

            # Resultado formateado para clasificacion
           #char = cv2.subtract(255, char)

            # Cambiar el tamaño de la imagen a 24x44 con borde negro
            char_copy[2:42, 2:22] = char
            char_copy[0:2, :] = 0
            char_copy[:, 0:2] = 0
            char_copy[42:44, :] = 0
            char_copy[:, 22:24] = 0

            img_res.append(char_copy) # Lista que almacena la imagen binaria del caracter
            
    # Devuelve caracteres en orden ascendente con respecto a la coordenada x
            
    plt.show()
    # arbitrary function that stores sorted list of character indeces
    indices = sorted(range(len(x_cntr_list)), key=lambda k: x_cntr_list[k])
    img_res_copy = []
    for idx in indices:
        img_res_copy.append(img_res[idx])# Almacena las imagenes del caracter de acuerdo a su indice
    img_res = np.array(img_res_copy)

    return img_res

def fix_dimension(img): 
  new_img = np.zeros((64,64,3))
  for i in range(3):
    new_img[:,:,i] = img
  return new_img

  # Utiliza el modelo para clasificar las imagenes de los numeros

def fix_dimension(img): 
  new_img = np.zeros((64,64,3))
  for i in range(3):
    new_img[:,:,i] = img
  return new_img
  
def show_results():
    dic = {}
    characters = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'
    
    for i,c in enumerate(characters):
        dic[i] = c

    output = []
    for i,ch in enumerate(char_test): #iteraccion sobre los cada uno de los caracteres
        img_ = cv2.resize(ch, (64,64), interpolation=cv2.INTER_AREA)
        img = fix_dimension(img_)
        img = img.reshape(1,64,64,3) #Prepera la imagen para ingresar al modelo

        pred = model.predict(img)[0] # Realiza la clasificación
        pred = np.argmax(pred,axis=0)

        character = dic[pred]
        output.append(character) # Guarda el resultado en una lista
       
    numero_placa = "".join([str(n) for n in output])
    
    return numero_placa

print('El numero de la placa es:', show_results())
  
return preds

@app.route('/', methods=['GET'])
def index():
    # Main page
    return render_template('index.html')


@app.route('/predict', methods=['GET', 'POST'])
def upload():
    if request.method == 'POST':
        # Get the file from post request
        f = request.files['file']

        # Save the file to ./uploads
        basepath = os.path.dirname(__file__)
        file_path = os.path.join(
            basepath, 'uploads', secure_filename(f.filename))
        f.save(file_path)

        # Make prediction
        preds = model_predict(file_path, model)

        # Process your result for human
        pred_class = preds.argmax(axis=-1)            # Simple argmax
        #pred_class = decode_predictions(preds, top=1)   # ImageNet Decode
        result = str(pred_class[0][0][1])               # Convert to string
        return result
    return None


if __name__ == '__main__':
    app.run(debug=True)
